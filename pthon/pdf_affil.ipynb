{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ce464-6125-4258-b7c3-f3b376f46d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /opt/homebrew/opt/ollama/bin/ollama serve\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbed5ba-3a2a-46ea-b8b9-e293cfac7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q --isolated openreview-py PyPDF2 chromadb\n",
    "\n",
    "import openreview\n",
    "\n",
    "# API V2\n",
    "client = openreview.api.OpenReviewClient(  # type: ignore\n",
    "    baseurl=\"https://api2.openreview.net\", username=email, password=\"\"\n",
    ")\n",
    "# venue_id = \"ICLR.cc/2024/Conference\"\n",
    "venue_id = \"ICML.cc/2024/Conference\"\n",
    "venue_group = client.get_group(venue_id)\n",
    "\n",
    "\n",
    "def get_submissions():\n",
    "    submissions = client.get_all_notes(content={\"venueid\": venue_id}, details=\"replies\")\n",
    "    return submissions\n",
    "\n",
    "\n",
    "review_name = venue_group.content[\"review_name\"][\"value\"]\n",
    "submission_name = venue_group.content[\"submission_name\"][\"value\"]\n",
    "\n",
    "\n",
    "def get_reviews(s):\n",
    "    reviews = [\n",
    "        openreview.api.Note.from_json(reply).content  # type: ignore\n",
    "        for reply in s.details[\"replies\"]\n",
    "        if f\"{venue_id}/{submission_name}{s.number}/-/{review_name}\"\n",
    "        in reply[\"invitations\"]\n",
    "    ]\n",
    "    return reviews\n",
    "\n",
    "\n",
    "submissions = get_submissions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b118075-5c02-43f0-b124-60ed149df266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import PyPDF2\n",
    "import requests\n",
    "\n",
    "\n",
    "def remove_surrogates(text):\n",
    "    return re.sub(r\"[\\ud800-\\udfff]\", \"\", text)\n",
    "\n",
    "\n",
    "def download_pdf(pdf_link):\n",
    "    response = requests.get(pdf_link)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(\"temp.pdf\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to download the PDF. Status code: {response.status_code}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def extract_pdf_text(pdf_file):\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "    text = []\n",
    "\n",
    "    for page in range(1):\n",
    "        page_obj = pdf_reader.pages[page]\n",
    "        text.append(page_obj.extract_text())\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "def find_references_start(parsed_text):\n",
    "    patterns = [\n",
    "        r\"(?i)(\\n|\\r\\n|\\r|\\.\\s|-\\s|\\*\\s|\\.)(References)\",\n",
    "        r\"(?i)(\\n|\\r\\n|\\r|\\.\\s|-\\s|\\*\\s|\\.)(Bibliography)\",\n",
    "        r\"(?i)(\\n|\\r\\n|\\r|\\.\\s|-\\s|\\*\\s|\\.)(Acknowledgements)\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, parsed_text)\n",
    "        if match:\n",
    "            return match.start() + len(match.group(1))\n",
    "    return -1\n",
    "\n",
    "\n",
    "def process_paper(pdf_link):\n",
    "    if download_pdf(pdf_link):\n",
    "        with open(\"temp.pdf\", \"rb\") as pdf_file:\n",
    "            text = extract_pdf_text(pdf_file)\n",
    "        os.remove(\"temp.pdf\")\n",
    "        text = text[: find_references_start(text)]\n",
    "        text = remove_surrogates(text)\n",
    "        return text[: text.find(\"Proceedings of the 41\")]\n",
    "        # return text.replace(\"\\n\", \"\")\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a24e2-4815-455d-a3fe-e2b765f3be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"author1\": [\"affiliation1\", \"affiliation2_if_exists\", \"...\"],\n",
    "    \"author2\": [\"...\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a907c99-d500-49f8-8feb-28b06fca21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "with open(\"llm_papers.json\") as json_file:\n",
    "    llm_papers = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8312f-b2d5-41b9-81ad-0729352d1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in tqdm(submissions):\n",
    "    if s.id in llm_papers:\n",
    "        continue\n",
    "    pdf_link = f\"https://openreview.net/{s.content['pdf']['value']}\"\n",
    "    t = process_paper(pdf_link)\n",
    "    prompt = f\"\"\"Extract authors and affiliations from the paper below. Return a valid dictionary only in the following format:\n",
    "    {schema}\n",
    "    Do not add any numbers from the reference, only the affiliation name. \n",
    "    Paper: {t}\n",
    "    \"\"\"\n",
    "    response = ollama.generate(model=\"gemma2\", prompt=prompt)[\"response\"]\n",
    "    try:\n",
    "        response = json.loads(response)\n",
    "        llm_papers[s.id] = response\n",
    "    except json.JSONDecodeError as e:\n",
    "        try:\n",
    "            response = eval(response)\n",
    "            llm_papers[s.id] = response\n",
    "        except Exception as e2:\n",
    "            print(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e31da6-1f22-48d9-91e5-fee0f56280c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe10003-a4a7-4790-9260-350a3b0e9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"llm_papers.json\", \"w\") as json_file:\n",
    "    json.dump(llm_papers, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986ce95-549b-44fb-b743-ab223f2f4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(llm_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b78a91-6315-420a-926e-13c62fcfeb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "def calculate_statistics(data: Dict[int, Dict]) -> Dict:\n",
    "    stats = {\n",
    "        \"total_authors\": len(data),\n",
    "        \"authors_per_institution\": collections.defaultdict(set),\n",
    "        \"authors_per_country\": collections.defaultdict(set),\n",
    "        \"multi_affiliation_authors\": 0,\n",
    "        \"institution_count\": collections.Counter(),\n",
    "        \"country_count\": collections.Counter(),\n",
    "    }\n",
    "\n",
    "    for aid, author_data in data.items():\n",
    "        institutions = author_data[\"institutions\"]\n",
    "\n",
    "        if len(institutions) > 1:\n",
    "            stats[\"multi_affiliation_authors\"] += 1\n",
    "\n",
    "        for inst in institutions:\n",
    "            if \"name\" in inst:\n",
    "                stats[\"authors_per_institution\"][inst[\"name\"]].add(aid)\n",
    "                stats[\"institution_count\"][inst[\"name\"]] += 1\n",
    "            if \"country\" in inst:\n",
    "                stats[\"authors_per_country\"][inst[\"country\"]].add(aid)\n",
    "                stats[\"country_count\"][inst[\"country\"]] += 1\n",
    "\n",
    "    # Convert sets to counts\n",
    "    stats[\"authors_per_institution\"] = {\n",
    "        k: len(v) for k, v in stats[\"authors_per_institution\"].items()\n",
    "    }\n",
    "    stats[\"authors_per_country\"] = {\n",
    "        k: len(v) for k, v in stats[\"authors_per_country\"].items()\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def print_statistics(stats: Dict):\n",
    "    print(f\"Total number of authors: {stats['total_authors']}\")\n",
    "    print(\n",
    "        f\"Number of authors with multiple affiliations: {stats['multi_affiliation_authors']}\"\n",
    "    )\n",
    "    print(\"\\nTop 15 institutions by author count:\")\n",
    "    for inst, count in sorted(\n",
    "        stats[\"authors_per_institution\"].items(), key=lambda x: x[1], reverse=True\n",
    "    )[:15]:\n",
    "        print(f\"  {inst}: {count}\")\n",
    "    print(\"\\nTop 15 countries by author count:\")\n",
    "    for country, count in sorted(\n",
    "        stats[\"authors_per_country\"].items(), key=lambda x: x[1], reverse=True\n",
    "    )[:15]:\n",
    "        print(f\"  {country}: {count}\")\n",
    "    print(\"\\nTotal number of unique institutions:\", len(stats[\"institution_count\"]))\n",
    "    print(\"Total number of unique countries:\", len(stats[\"country_count\"]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    statistics = calculate_statistics(llm_papers)\n",
    "    print_statistics(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167ba5b-dfe2-4084-ac63-082cb8af0005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ee070-08cc-444e-acde-617e3a7a11e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
